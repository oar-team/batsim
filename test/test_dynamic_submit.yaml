base_output_directory: /tmp/batsim_tests/dynamic_submit

base_variables:
    batsim_dir: ${base_working_directory}

implicit_instances:
  # Algorithms without parameters
  noparam:
    sweep:
      platform :
        # Disabled as long obfh is not solved (https://github.com/oar-team/batsim/issues/21)
        #- {"name":"homo1", "filename":"${batsim_dir}/platforms/energy_platform_homogeneous_no_net_1.xml", "master_node":"master_host"}
        - {"name":"small", "filename":"${batsim_dir}/platforms/small_platform.xml", "master_node":"master_host"}
        - {"name":"cluster", "filename":"${batsim_dir}/platforms/cluster512.xml", "master_node":"master_host0"}
      nb_dyn_jobs: [0,1,10]
      energy:
        #- {"name": "enabled", "option":"-E "}
        - {"name": "disabled", "option":""}
      algo:
        - {"name":"submitter", "sched_name":"submitter"}
      workload:
        - {"name":"one_job", "filename":"${batsim_dir}/workload_profiles/one_delay_job.json"}
      mode:
        - {"name":"diff_profiles__bundledp", "increase_jobs_duration":"true", "send_profile_if_already_sent":"true", "send_profiles_in_separate_event":"false"}
        - {"name":"diff_profiles__separatep", "increase_jobs_duration":"true", "send_profile_if_already_sent":"true", "send_profiles_in_separate_event":"true"}
        - {"name":"same_profiles__resend__bundledp", "increase_jobs_duration":"false", "send_profile_if_already_sent":"true", "send_profiles_in_separate_event":"false"}
        - {"name":"same_profiles__resend__separatep", "increase_jobs_duration":"false", "send_profile_if_already_sent":"true", "send_profiles_in_separate_event":"true"}
        - {"name":"same_profiles__no_resend__bundledp", "increase_jobs_duration":"false", "send_profile_if_already_sent":"false", "send_profiles_in_separate_event":"false"}
        - {"name":"same_profiles__no_resend__separatep", "increase_jobs_duration":"false", "send_profile_if_already_sent":"false", "send_profiles_in_separate_event":"true"}
      redis_enabled: ["true", "false"]
      dynamic_submit_ack: ["true", "false"]
    generic_instance:
      variables:
        socket_port: "$((${instance_number} + 28000))"
      timeout: 3600
      working_directory: ${base_working_directory}
      output_directory: ${base_output_directory}/results/${instance_id}
      batsim_command: batsim -p ${platform[filename]} -w ${workload[filename]} ${energy[option]} -e ${output_directory}/out --mmax-workload --config-file ${output_directory}/batsim.conf -vdebug -m ${platform[master_node]} -s "tcp://localhost:${socket_port}"
      sched_command: batsched -v ${algo[sched_name]} --variant_options_filepath ${output_directory}/sched_input.json -s "tcp://*:${socket_port}"
      commands_before_execution:
        # Generate Batsim config file
        - |
              #!/usr/bin/env bash
              cat > ${output_directory}/batsim.conf << EOF
              {
                "redis": {
                  "enabled": ${redis_enabled}
                },
                "job_submission": {
                  "forward_profiles": false,
                  "from_scheduler":{
                    "enabled": true,
                    "acknowledge": ${dynamic_submit_ack}
                  }
                }
              }
              EOF
        # Generate sched input
        - |
            #!/usr/bin/env bash
            source ${output_directory}/variables.bash
            cat > ${output_directory}/sched_input.json << EOF
            {
              "nb_jobs_to_submit": ${nb_dyn_jobs},
              "increase_jobs_duration": ${mode[increase_jobs_duration]},
              "send_profile_if_already_sent": ${mode[send_profile_if_already_sent]}
            }
            EOF

      commands_after_execution:
        # Checks whether:
        #  - the number of dynamic jobs is fine
        #  - the dynamic jobs have correct execution time
        - |
            #!/usr/bin/env bash
            source ${output_directory}/variables.bash

            cat > ${output_directory}/jobs_analysis.R <<EOF
            #!/usr/bin/env Rscript
            library(dplyr)

            # Let's get when jobs have been released
            jobs = read.csv('${output_directory}/out_jobs.csv')

            nb_expected_dynamic_jobs = ${nb_dyn_jobs}
            dynamic_jobs = jobs %>% filter(workload_name == 'dynamic')

            # Let's check the number of dynamic jobs
            if (nrow(dynamic_jobs) != nb_expected_dynamic_jobs) {
                stop(sprintf("Expecting %d dynamic jobs but %d have been found", nb_expected_dynamic_jobs, nrow(dynamic_jobs)))
            } else {
                sprintf("There are %d dynamic jobs (as expected)", nb_expected_dynamic_jobs)
            }

            # Let's check the dynamic jobs execution times
            if(toupper("${mode[increase_jobs_duration]}") == TRUE) {
                dynamic_jobs['expected_execution_time'] = dynamic_jobs['job_id'] * 10 + 1
            } else {
                # Using dynamic_jobs['job_id'] * 0 to conserve a vector of the good length
                dynamic_jobs['expected_execution_time'] = dynamic_jobs['job_id'] * 0 + 1
            }

            ok_runtime = dynamic_jobs %>% filter(execution_time == expected_execution_time)
            bad_runtime = dynamic_jobs %>% filter(execution_time != expected_execution_time)
            if (nrow(bad_runtime) > 0) {
                print("Some jobs do NOT match their expected execution time")
                print(bad_runtime %>% select(-requested_number_of_processors,
                                             -success,
                                             -waiting_time,
                                             -stretch,
                                             -allocated_processors,
                                             -hacky_job_id,
                                             -submission_time,
                                             -requested_time,
                                             -starting_time,
                                             -finish_time,
                                             -turnaround_time,
                                             -consumed_energy))
                stop("Aborting")
            } else {
                sprintf("All the jobs match their expected execution time")
            }

            EOF
        - chmod +x ${output_directory}/jobs_analysis.R
        - ${output_directory}/jobs_analysis.R

commands_before_instances:
  - ${batsim_dir}/test/is_batsim_dir.py ${base_working_directory}
  - ${batsim_dir}/test/clean_output_dir.py ${base_output_directory}

commands_after_instances:
  - |
      #!/usr/bin/env bash
      source ${base_output_directory}/variables.bash

      cat > ${base_output_directory}/instances_analysis.R <<EOF
      #!/usr/bin/env Rscript
      library(dplyr)
      instances = read.csv("/tmp/batsim_tests/dynamic_submit/instances/instances_info.csv")

      # Remove garbage
      instances = instances %>% select(-platform__master_node, -platform__filename,
                                       -instance_number, -instance_name,
                                       -explicit, -algo__name, -algo__sched_name,
                                       -energy__option)

      # Sort
      instances = instances %>% arrange(platform__name, nb_dyn_jobs,
                                        dynamic_submit_ack, redis_enabled)

      works = instances %>% filter(status == 'done')
      crashes = instances %>% filter(status != 'done')

      print("WORKS:")
      print(works)

      print("CRASHES:")
      print(crashes)
      EOF
  - chmod +x ${base_output_directory}/instances_analysis.R
  - ${base_output_directory}/instances_analysis.R
